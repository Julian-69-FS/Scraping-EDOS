# Documentaci√≥n: Scripts de Procesamiento de Metadatos - Baja California

> **Ubicaci√≥n de los scripts:** `C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\metadatos`
> **Fecha de documentaci√≥n:** Noviembre 2025
> **Autor original:** Julian
> **Prop√≥sito:** Procesamiento avanzado de PDFs legales para extracci√≥n y consolidaci√≥n de metadatos

---

## √çndice

1. [Descripci√≥n General](#1-descripci√≥n-general)
2. [Requisitos y Dependencias](#2-requisitos-y-dependencias)
3. [Estructura de Archivos](#3-estructura-de-archivos)
4. [Arquitectura del C√≥digo](#4-arquitectura-del-c√≥digo)
5. [Clase ReglamentoProcessor](#5-clase-reglamentoprocessor)
6. [M√©todos Principales](#6-m√©todos-principales)
7. [Rutas de Entrada y Salida](#7-rutas-de-entrada-y-salida)
8. [Flujo de Ejecuci√≥n](#8-flujo-de-ejecuci√≥n)
9. [Estructura de Datos de Salida](#9-estructura-de-datos-de-salida)
10. [T√©cnicas de Extracci√≥n de Texto](#10-t√©cnicas-de-extracci√≥n-de-texto)
11. [Sistema de Matching (Correspondencia)](#11-sistema-de-matching-correspondencia)
12. [C√≥mo Ejecutar](#12-c√≥mo-ejecutar)
13. [Consideraciones Importantes](#13-consideraciones-importantes)
14. [Posibles Errores y Soluciones](#14-posibles-errores-y-soluciones)

---

## 1. Descripci√≥n General

Esta carpeta contiene **tres scripts especializados** para el procesamiento avanzado de documentos legales en formato PDF. Su funci√≥n principal es:

1. **Extraer texto** de PDFs (incluyendo documentos escaneados mediante OCR)
2. **Detectar y procesar tablas** dentro de los documentos
3. **Combinar informaci√≥n** de m√∫ltiples fuentes JSON (contenido + metadatos del scraping)
4. **Generar archivos JSON individuales** con toda la informaci√≥n consolidada

### ¬øQu√© problema resuelven?

Estos scripts act√∫an como el **paso final del pipeline de procesamiento**, tomando:
- Los PDFs descargados por los scripts de scraping
- Los metadatos extra√≠dos durante el scraping (`json_metadatos/`)
- El contenido textual previamente procesado (`contenido/`)

Y produciendo archivos JSON completos y estructurados para cada documento legal.

### Diferencia con otros scripts

| Carpeta | Funci√≥n |
|---------|---------|
| `scraping/` | Descarga PDFs y extrae metadatos b√°sicos de las p√°ginas web |
| `scrips/` | Extrae contenido textual de los PDFs |
| **`metadatos/`** | **Consolida todo: PDFs + contenido + metadatos ‚Üí JSON final** |

---

## 2. Requisitos y Dependencias

### Python
- **Versi√≥n requerida:** Python 3.8 o superior

### Librer√≠as necesarias

```bash
pip install PyPDF2
pip install pdfplumber
pip install PyMuPDF
pip install pdfminer.six
pip install tabula-py
pip install easyocr
pip install numpy
pip install Pillow
```

### Tabla de dependencias

| Librer√≠a | Versi√≥n | Prop√≥sito |
|----------|---------|-----------|
| `PyPDF2` | >= 3.0 | Extracci√≥n b√°sica de texto PDF |
| `pdfplumber` | >= 0.9 | Extracci√≥n avanzada y detecci√≥n de tablas |
| `PyMuPDF` (fitz) | >= 1.22 | Extracci√≥n de alta calidad y conversi√≥n a imagen |
| `pdfminer.six` | >= 20221105 | Extracci√≥n con control de layout |
| `tabula-py` | >= 2.7 | Extracci√≥n de tablas (requiere Java) |
| `easyocr` | >= 1.7 | OCR para documentos escaneados |
| `numpy` | >= 1.24 | Manipulaci√≥n de arrays para im√°genes |
| `Pillow` | >= 9.5 | Procesamiento de im√°genes |

### Software adicional requerido
- **Java Runtime Environment (JRE):** Necesario para `tabula-py`

### Verificar instalaci√≥n

```bash
python --version
pip list | grep -E "PyPDF2|pdfplumber|PyMuPDF|pdfminer|tabula|easyocr|numpy|Pillow"
java -version
```

---

## 3. Estructura de Archivos

```
BAJA CALIFORNIA/
‚îú‚îÄ‚îÄ metadatos/
‚îÇ   ‚îú‚îÄ‚îÄ codigos.py          # Procesador para c√≥digos (~60KB, 1293 l√≠neas)
‚îÇ   ‚îú‚îÄ‚îÄ leyes.py            # Procesador para leyes (~60KB, 1299 l√≠neas)
‚îÇ   ‚îî‚îÄ‚îÄ reglamentos.py      # Procesador para reglamentos (~60KB, 1294 l√≠neas)
‚îÇ
‚îú‚îÄ‚îÄ json_metadatos/         # ENTRADA: Metadatos del scraping
‚îÇ   ‚îú‚îÄ‚îÄ metadatos_codigos.json
‚îÇ   ‚îú‚îÄ‚îÄ metadatos_leyes.json
‚îÇ   ‚îî‚îÄ‚îÄ metadatos_reglamentos.json
‚îÇ
‚îú‚îÄ‚îÄ contenido/              # ENTRADA: Contenido textual procesado
‚îÇ   ‚îú‚îÄ‚îÄ codigo-contenido.json
‚îÇ   ‚îú‚îÄ‚îÄ leyes-contenido.json
‚îÇ   ‚îî‚îÄ‚îÄ reglamentos-contenido.json
‚îÇ
‚îî‚îÄ‚îÄ json/                   # SALIDA: JSONs finales individuales
    ‚îú‚îÄ‚îÄ Codigos/
    ‚îú‚îÄ‚îÄ Leyes/
    ‚îî‚îÄ‚îÄ Reglamentos/
```

---

## 4. Arquitectura del C√≥digo

### Diagrama de flujo general

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PDFs origen   ‚îÇ     ‚îÇ  contenido.json ‚îÇ     ‚îÇ metadatos.json  ‚îÇ
‚îÇ  (descargados)  ‚îÇ     ‚îÇ (texto previo)  ‚îÇ     ‚îÇ   (scraping)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   ReglamentoProcessor  ‚îÇ
                    ‚îÇ                        ‚îÇ
                    ‚îÇ  ‚Ä¢ Extrae texto PDF    ‚îÇ
                    ‚îÇ  ‚Ä¢ Detecta tablas      ‚îÇ
                    ‚îÇ  ‚Ä¢ Aplica OCR si es    ‚îÇ
                    ‚îÇ    escaneado           ‚îÇ
                    ‚îÇ  ‚Ä¢ Busca matching con  ‚îÇ
                    ‚îÇ    contenido/metadatos ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   JSON Individual      ‚îÇ
                    ‚îÇ   por documento        ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Patr√≥n de dise√±o

Los scripts utilizan una **clase √∫nica `ReglamentoProcessor`** que encapsula toda la l√≥gica de procesamiento. Esta clase implementa:

- **Strategy Pattern:** M√∫ltiples m√©todos de extracci√≥n de texto que se intentan en orden
- **Template Method:** El m√©todo `process_all_pdfs()` define el flujo, delegando a m√©todos espec√≠ficos

---

## 5. Clase ReglamentoProcessor

### Definici√≥n

```python
class ReglamentoProcessor:
    """Procesador especializado para Reglamentos y Leyes Federales Mexicanas"""
```

### Atributos principales

| Atributo | Tipo | Descripci√≥n |
|----------|------|-------------|
| `input_folder` | `Path` | Carpeta con los PDFs a procesar |
| `output_folder` | `Path` | Carpeta donde se guardan los JSONs |
| `contenido_json_path` | `Path` | Ruta al JSON con contenido textual previo |
| `metadatos_json_path` | `Path` | Ruta al JSON con metadatos del scraping |
| `contenido_data` | `List[Dict]` | Datos de contenido cargados en memoria |
| `metadatos_data` | `List[Dict]` | Datos de metadatos cargados en memoria |
| `ocr_reader` | `easyocr.Reader` | Lector OCR (inicializaci√≥n lazy) |

### Constructor

```python
def __init__(self, input_folder: str, output_folder: str):
    self.input_folder = Path(input_folder)
    self.output_folder = Path(output_folder)

    # Rutas a JSONs de entrada (var√≠an por script)
    self.contenido_json_path = Path(r"...\contenido\codigo-contenido.json")
    self.metadatos_json_path = Path(r"...\json_metadatos\metadatos_codigos.json")

    # Datos en memoria
    self.contenido_data = []
    self.metadatos_data = []

    # OCR (lazy loading)
    self.ocr_reader = None

    # Crear carpeta de salida
    self.output_folder.mkdir(parents=True, exist_ok=True)
```

---

## 6. M√©todos Principales

### 6.1 M√©todos de carga de datos

#### `load_contenido_data()`
Carga el archivo JSON con el contenido textual previamente extra√≠do.

```python
def load_contenido_data(self) -> None:
    if self.contenido_json_path.exists():
        with open(self.contenido_json_path, 'r', encoding='utf-8') as f:
            self.contenido_data = json.load(f)
```

#### `load_metadatos_data()`
Carga el archivo JSON con los metadatos extra√≠dos durante el scraping.

```python
def load_metadatos_data(self) -> None:
    if self.metadatos_json_path.exists():
        with open(self.metadatos_json_path, 'r', encoding='utf-8') as f:
            self.metadatos_data = json.load(f)
```

### 6.2 M√©todos de extracci√≥n de texto

El script implementa **m√∫ltiples m√©todos de extracci√≥n** que se intentan en orden de prioridad:

#### `extract_text_with_pymupdf(pdf_path, max_pages=5)`
Extracci√≥n usando PyMuPDF (fitz). Generalmente el m√°s r√°pido y confiable.

#### `extract_text_with_pdfminer(pdf_path, max_pages=5)`
Extracci√≥n usando pdfminer con control de layout.

#### `extract_text_with_pdfplumber(pdf_path, max_pages=5)`
Extracci√≥n usando pdfplumber, mejor para documentos con estructura compleja.

#### `extract_text_combined(pdf_path, max_pages=5)`
**M√©todo principal.** Intenta m√∫ltiples extractores y devuelve el mejor resultado.

```python
def extract_text_combined(self, pdf_path: Path, max_pages: int = 5) -> Tuple[str, bool]:
    """
    Extrae texto combinando m√∫ltiples m√©todos

    Returns:
        Tuple[str, bool]: (texto_extra√≠do, es_escaneado)
    """
    methods = [
        ('PyMuPDF', self.extract_text_with_pymupdf),
        ('PDFMiner', self.extract_text_with_pdfminer),
        ('pdfplumber', self.extract_text_with_pdfplumber)
    ]

    for name, method in methods:
        text = method(pdf_path, max_pages)
        if text and len(text.strip()) > 100:
            return text, False  # No es escaneado

    # Si ning√∫n m√©todo funcion√≥, usar OCR
    return self.extract_text_with_ocr(pdf_path, max_pages), True
```

#### `extract_text_with_ocr(pdf_path, max_pages=3)`
OCR usando EasyOCR para documentos escaneados.

```python
def extract_text_with_ocr(self, pdf_path: Path, max_pages: int = 3) -> str:
    if self.ocr_reader is None:
        self.ocr_reader = easyocr.Reader(['es'], gpu=False)

    doc = fitz.open(pdf_path)
    full_text = []

    for page_num in range(min(len(doc), max_pages)):
        page = doc[page_num]
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        results = self.ocr_reader.readtext(np.array(img))
        page_text = ' '.join([result[1] for result in results])
        full_text.append(page_text)

    return '\n'.join(full_text)
```

### 6.3 M√©todos de detecci√≥n de tablas

#### `detect_tables(pdf_path, max_pages=3)`
Detecta si el PDF contiene tablas usando pdfplumber.

```python
def detect_tables(self, pdf_path: Path, max_pages: int = 3) -> bool:
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages[:max_pages]:
            tables = page.extract_tables()
            if tables:
                return True
    return False
```

### 6.4 M√©todos de matching (correspondencia)

#### `find_matching_contenido(titulo)`
Busca el contenido textual correspondiente al t√≠tulo del documento usando **similitud de cadenas**.

```python
def find_matching_contenido(self, titulo: str) -> Optional[str]:
    """
    Busca en contenido_data el registro que mejor coincida con el t√≠tulo
    """
    titulo_normalizado = self.normalize_text(titulo)
    best_match = None
    best_ratio = 0.0

    for item in self.contenido_data:
        item_titulo = item.get('titulo', '')
        item_normalizado = self.normalize_text(item_titulo)

        ratio = SequenceMatcher(None, titulo_normalizado, item_normalizado).ratio()

        if ratio > best_ratio and ratio > 0.7:  # Umbral m√≠nimo 70%
            best_ratio = ratio
            best_match = item.get('contenido')

    return best_match
```

#### `find_matching_metadatos(titulo)`
Busca los metadatos correspondientes del archivo de scraping.

```python
def find_matching_metadatos(self, titulo: str) -> Optional[Dict]:
    """
    Busca en metadatos_data el registro que mejor coincida con el t√≠tulo
    """
    titulo_normalizado = self.normalize_text(titulo)
    best_match = None
    best_ratio = 0.0

    for item in self.metadatos_data:
        # Diferentes scripts usan diferentes campos
        item_titulo = item.get('titulo') or item.get('NOMBRE', '')
        item_normalizado = self.normalize_text(item_titulo)

        ratio = SequenceMatcher(None, titulo_normalizado, item_normalizado).ratio()

        if ratio > best_ratio and ratio > 0.7:
            best_ratio = ratio
            best_match = item

    return best_match
```

#### `normalize_text(text)`
Normaliza texto para mejorar la comparaci√≥n.

```python
def normalize_text(self, text: str) -> str:
    """Normaliza texto removiendo acentos y caracteres especiales"""
    text = text.lower().strip()
    text = unicodedata.normalize('NFD', text)
    text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text
```

### 6.5 M√©todos de procesamiento

#### `process_single_pdf(pdf_path)`
Procesa un √∫nico PDF y devuelve un diccionario con los datos extra√≠dos.

```python
def process_single_pdf(self, pdf_path: Path) -> Dict[str, Any]:
    """Procesa un √∫nico PDF y extrae toda la informaci√≥n"""

    # Extraer texto
    text, es_escaneado = self.extract_text_combined(pdf_path)

    # Detectar tablas
    tiene_tablas = self.detect_tables(pdf_path)

    # Extraer t√≠tulo del nombre del archivo
    titulo = self.extract_title_from_filename(pdf_path.name)

    return {
        'titulo': titulo,
        'ordenamiento': 'LEY',  # o 'CODIGO', 'REGLAMENTO' seg√∫n script
        'jurisdiccion': 'ESTATAL',
        'fuente_oficial': 'BAJA CALIFORNIA',
        'es_escaneado': es_escaneado,
        'tiene_tablas': tiene_tablas
    }
```

#### `process_all_pdfs()`
Procesa todos los PDFs en la carpeta de entrada.

```python
def process_all_pdfs(self) -> List[Dict]:
    """Procesa todos los PDFs en la carpeta de entrada"""

    # Cargar datos auxiliares
    self.load_contenido_data()
    self.load_metadatos_data()

    resultados = []
    pdf_files = list(self.input_folder.glob('*.pdf'))

    for i, pdf_path in enumerate(pdf_files, 1):
        print(f"Procesando {i}/{len(pdf_files)}: {pdf_path.name}")

        try:
            result = self.process_single_pdf(pdf_path)

            # Buscar contenido y metadatos correspondientes
            contenido = self.find_matching_contenido(result['titulo'])
            metadatos = self.find_matching_metadatos(result['titulo'])

            # Crear resultado ordenado
            ordered_result = self.create_ordered_result(result, contenido, metadatos)

            # Guardar JSON individual
            self.save_individual_json(ordered_result, pdf_path.stem)

            resultados.append(ordered_result)

        except Exception as e:
            logger.error(f"Error procesando {pdf_path.name}: {e}")
            continue

    return resultados
```

---

## 7. Rutas de Entrada y Salida

### Script: `codigos.py`

| Tipo | Ruta |
|------|------|
| **INPUT (PDFs)** | `C:\Users\julii\Documents\BAJA CALIFORNIA\Codigos` |
| **OUTPUT (JSONs)** | `C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Codigos` |
| **Contenido JSON** | `...\contenido\codigo-contenido.json` |
| **Metadatos JSON** | `...\json_metadatos\metadatos_codigos.json` |

### Script: `leyes.py`

| Tipo | Ruta |
|------|------|
| **INPUT (PDFs)** | `C:\Users\julii\Documents\BAJA CALIFORNIA\Leyes` |
| **OUTPUT (JSONs)** | `C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Leyes` |
| **Contenido JSON** | `...\contenido\leyes-contenido.json` |
| **Metadatos JSON** | `...\json_metadatos\metadatos_leyes.json` |

### Script: `reglamentos.py`

| Tipo | Ruta |
|------|------|
| **INPUT (PDFs)** | `C:\Users\julii\Documents\BAJA CALIFORNIA\Reglamentos` |
| **OUTPUT (JSONs)** | `C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Reglamentos` |
| **Contenido JSON** | `...\contenido\reglamentos-contenido.json` |
| **Metadatos JSON** | `...\json_metadatos\metadatos_reglamentos.json` |

### ‚ö†Ô∏è IMPORTANTE: Rutas a modificar

Antes de ejecutar, modificar estas variables en cada script:

```python
# En main():
INPUT_FOLDER = r"NUEVA_RUTA\A\PDFs"
OUTPUT_FOLDER = r"NUEVA_RUTA\A\json"

# En __init__():
self.contenido_json_path = Path(r"NUEVA_RUTA\contenido.json")
self.metadatos_json_path = Path(r"NUEVA_RUTA\metadatos.json")
```

---

## 8. Flujo de Ejecuci√≥n

### Diagrama de flujo detallado

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         main()                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Crear instancia ReglamentoProcessor(INPUT, OUTPUT)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Cargar datos auxiliares:                                   ‚îÇ
‚îÇ     - load_contenido_data()                                    ‚îÇ
‚îÇ     - load_metadatos_data()                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Para cada PDF en INPUT_FOLDER:                             ‚îÇ
‚îÇ     ‚îî‚îÄ‚ñ∫ process_single_pdf()                                   ‚îÇ
‚îÇ         ‚îú‚îÄ‚ñ∫ extract_text_combined()                            ‚îÇ
‚îÇ         ‚îÇ   ‚îú‚îÄ‚ñ∫ PyMuPDF                                        ‚îÇ
‚îÇ         ‚îÇ   ‚îú‚îÄ‚ñ∫ PDFMiner                                       ‚îÇ
‚îÇ         ‚îÇ   ‚îú‚îÄ‚ñ∫ pdfplumber                                     ‚îÇ
‚îÇ         ‚îÇ   ‚îî‚îÄ‚ñ∫ OCR (si es necesario)                          ‚îÇ
‚îÇ         ‚îî‚îÄ‚ñ∫ detect_tables()                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Buscar correspondencias:                                   ‚îÇ
‚îÇ     - find_matching_contenido(titulo)                          ‚îÇ
‚îÇ     - find_matching_metadatos(titulo)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Crear resultado ordenado con todos los campos              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. Guardar JSON individual en OUTPUT_FOLDER                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 9. Estructura de Datos de Salida

### Para `leyes.py` (usando metadatos del Congreso)

```json
{
  "titulo": "Ley de Acceso de las Mujeres a una Vida Libre de Violencia",
  "Contenido": "Texto completo del documento...",
  "ordenamiento": "LEY",
  "jurisdiccion": "ESTATAL",
  "fuente_oficial": "BAJA CALIFORNIA",
  "FECHA PER OFIC": "2008-07-25",
  "ESTATUS": "Vigente",
  "TOMO": "CXIV",
  "URL": "https://www.congresobc.gob.mx/...",
  "es_escaneado": false,
  "tiene_tablas": true
}
```

### Para `codigos.py` y `reglamentos.py` (usando metadatos del Poder Judicial)

```json
{
  "titulo": "C√≥digo Civil para el Estado de Baja California",
  "Contenido": "Texto completo del documento...",
  "ordenamiento": "CODIGO",
  "jurisdiccion": "ESTATAL",
  "fuente_oficial": "BAJA CALIFORNIA",
  "Fecha de √∫ltima modificaci√≥n": "2023-05-15",
  "Fecha de publicaci√≥n": "1974-03-01",
  "url": "https://transparencia.pjbc.gob.mx/...",
  "es_escaneado": false,
  "tiene_tablas": false
}
```

### Diferencias en estructura de metadatos

| Campo | leyes.py | codigos.py / reglamentos.py |
|-------|----------|----------------------------|
| T√≠tulo origen | `NOMBRE` | `titulo` |
| Fecha 1 | `FECHA PER OFIC` | `Fecha de √∫ltima modificaci√≥n` |
| Fecha 2 | - | `Fecha de publicaci√≥n` |
| Estado | `ESTATUS` | - |
| Tomo | `TOMO` | - |
| URL | `URL` | `url` |

---

## 10. T√©cnicas de Extracci√≥n de Texto

### Orden de prioridad

1. **PyMuPDF (fitz):** M√°s r√°pido, buena calidad general
2. **PDFMiner:** Mejor control de layout, √∫til para documentos complejos
3. **pdfplumber:** Excelente para tablas y estructura
4. **OCR (EasyOCR):** √öltimo recurso para documentos escaneados

### Criterio de selecci√≥n autom√°tica

```python
# El texto se considera v√°lido si tiene m√°s de 100 caracteres
if text and len(text.strip()) > 100:
    return text, False  # No es escaneado

# Si ning√∫n m√©todo extrae texto suficiente ‚Üí OCR
return self.extract_text_with_ocr(pdf_path), True  # Es escaneado
```

### Configuraci√≥n de OCR

```python
# EasyOCR configuraci√≥n
self.ocr_reader = easyocr.Reader(['es'], gpu=False)

# Zoom 2x para mejor calidad de imagen
pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
```

---

## 11. Sistema de Matching (Correspondencia)

### Algoritmo utilizado

Se utiliza `difflib.SequenceMatcher` para encontrar correspondencias por similitud de texto.

### Proceso de matching

```
1. Normalizar t√≠tulo del PDF:
   "LEY DE ACCESO..." ‚Üí "ley de acceso..."

2. Normalizar t√≠tulos en JSON de contenido/metadatos

3. Calcular ratio de similitud (0.0 a 1.0)

4. Si ratio > 0.7 (70%), considerar como match

5. Devolver el mejor match encontrado
```

### Normalizaci√≥n aplicada

```python
def normalize_text(text):
    text = text.lower().strip()           # Min√∫sculas
    text = unicodedata.normalize('NFD')   # Descomponer acentos
    text = ''.join(c for c if not accent) # Remover acentos
    text = re.sub(r'[^\w\s]', '', text)   # Solo alfanum√©ricos
    text = re.sub(r'\s+', ' ', text)      # Espacios simples
    return text
```

---

## 12. C√≥mo Ejecutar

### Prerrequisitos

1. **Archivos de entrada existentes:**
   - PDFs en la carpeta INPUT_FOLDER
   - `contenido.json` con el texto extra√≠do previamente
   - `metadatos.json` del scraping

2. **Dependencias instaladas:**
   ```bash
   pip install PyPDF2 pdfplumber PyMuPDF pdfminer.six tabula-py easyocr numpy Pillow
   ```

3. **Java instalado** (para tabula-py)

### Ejecuci√≥n individual

```bash
cd "C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\metadatos"

python codigos.py
python leyes.py
python reglamentos.py
```

### Ejecuci√≥n en secuencia

```bash
python codigos.py && python leyes.py && python reglamentos.py
```

### Procesar un solo archivo (modo debug)

Modificar en `main()`:

```python
# Descomentar estas l√≠neas:
pdf_name = "nombre_del_archivo.pdf"
pdf_path = Path(INPUT_FOLDER) / pdf_name
# ... resto del c√≥digo de procesamiento individual
```

### Verificar resultados

```bash
# Ver JSONs generados
dir "C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Codigos"
dir "C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Leyes"
dir "C:\Users\julii\Documents\Practicas\drive\BAJA CALIFORNIA\json\Reglamentos"

# Ver contenido de un JSON
type "...\json\Leyes\Ley_de_Ejemplo.json"
```

---

## 13. Consideraciones Importantes

### ‚ö†Ô∏è CR√çTICO

1. **Orden de ejecuci√≥n del pipeline:**
   ```
   1. Ejecutar scripts de scraping (descargar PDFs y metadatos)
   2. Ejecutar scripts de extracci√≥n (generar contenido.json)
   3. Ejecutar scripts de metadatos (consolidar todo)
   ```

2. **Memoria RAM:** EasyOCR puede consumir mucha memoria. Si hay problemas:
   - Reducir `max_pages` en el OCR
   - Procesar en lotes m√°s peque√±os

3. **Tiempo de ejecuci√≥n:** El OCR es lento. Documentos escaneados pueden tomar varios minutos cada uno.

4. **Umbral de matching:** El 70% de similitud puede no encontrar algunos matches. Ajustar si es necesario:
   ```python
   if ratio > 0.6:  # Bajar a 60% si hay muchos no-matches
   ```

### üìù NOTAS T√âCNICAS

1. **Lazy loading de OCR:** El lector OCR solo se inicializa cuando se necesita, ahorrando tiempo si no hay documentos escaneados.

2. **Logging:** Los scripts usan logging configurado a nivel INFO. Para debug:
   ```python
   logging.basicConfig(level=logging.DEBUG)
   ```

3. **Errores silenciosos:** Los errores en documentos individuales se registran pero no detienen el proceso.

4. **Archivos de salida:** Se nombran seg√∫n el nombre del PDF sin extensi√≥n.

### üîÑ MANTENIMIENTO

- **Actualizar cuando cambien los formatos** de los JSON de entrada
- **Verificar compatibilidad** de librer√≠as si se actualiza Python
- **Revisar umbrales de matching** si cambia la nomenclatura de documentos

---

## 14. Posibles Errores y Soluciones

### Error: "No module named 'fitz'"

**Causa:** PyMuPDF no instalado correctamente.

**Soluci√≥n:**
```bash
pip uninstall PyMuPDF
pip install PyMuPDF
```

### Error: "Java not found" (tabula-py)

**Causa:** Java no instalado o no en PATH.

**Soluci√≥n:**
1. Instalar Java JRE/JDK
2. Agregar a PATH: `C:\Program Files\Java\jdk-XX\bin`
3. Reiniciar terminal

### Error: "Could not find a valid CUDA"

**Causa:** EasyOCR intentando usar GPU.

**Soluci√≥n:** Ya est√° configurado `gpu=False`, pero si persiste:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
```

### Error: "MemoryError" durante OCR

**Causa:** Im√°genes muy grandes o muchas p√°ginas.

**Soluci√≥n:**
```python
# Reducir zoom
pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))  # En vez de 2x

# Reducir p√°ginas
max_pages = 2  # En vez de 3
```

### No encuentra matches (Contenido = None)

**Causa:** Los t√≠tulos no coinciden suficientemente.

**Soluci√≥n:**
1. Verificar que los JSON de entrada existen y tienen datos
2. Revisar la nomenclatura de t√≠tulos
3. Bajar el umbral de matching:
   ```python
   if ratio > 0.6:  # Bajar de 0.7 a 0.6
   ```

### PDFs procesados pero JSONs vac√≠os

**Causa:** Extracci√≥n de texto fall√≥ en todos los m√©todos.

**Soluci√≥n:**
1. Verificar que el PDF no est√° corrupto
2. Ejecutar en modo no-headless para ver errores
3. Probar extracci√≥n manual:
   ```python
   import fitz
   doc = fitz.open("archivo.pdf")
   print(doc[0].get_text())
   ```

---

## Resumen R√°pido

| Aspecto | Detalle |
|---------|---------|
| **Lenguaje** | Python 3.8+ |
| **Dependencias principales** | PyMuPDF, pdfplumber, EasyOCR, tabula-py |
| **Clase principal** | `ReglamentoProcessor` |
| **Entrada** | PDFs + contenido.json + metadatos.json |
| **Salida** | JSONs individuales por documento |
| **OCR** | EasyOCR (espa√±ol, sin GPU) |
| **Matching** | SequenceMatcher con umbral 70% |
| **Scripts** | codigos.py, leyes.py, reglamentos.py |

---

> **√öltima actualizaci√≥n de documentaci√≥n:** Noviembre 2025

